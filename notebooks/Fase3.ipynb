{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf39e9d-386a-43bd-ab4b-e5da48787830",
   "metadata": {},
   "source": [
    "# Fase 3: Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad18c9-3f27-4471-9e78-d86a35d13a7a",
   "metadata": {},
   "source": [
    "## Setup Kedro | Importación de librerías y carga de los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69f3a9d8-0a6b-4bb7-a8cf-227dd818eca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/13/25 22:26:59] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Kedro is sending anonymous usage data with the sole purpose of improving <a href=\"file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro_telemetry\\plugin.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">plugin.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro_telemetry\\plugin.py#243\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">243</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         the product. No personal data or IP addresses are stored on our side. To <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         opt out, set the `KEDRO_DISABLE_TELEMETRY` or `DO_NOT_TRACK` environment <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         variables, or create a `.telemetry` file in the current working          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         directory with the contents `consent: false`. To hide this message,      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         explicitly grant or deny consent. Read more at                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://docs.kedro.org/en/stable/configuration/telemetry.html</span>            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/13/25 22:26:59]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Kedro is sending anonymous usage data with the sole purpose of improving \u001b]8;id=438880;file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro_telemetry\\plugin.py\u001b\\\u001b[2mplugin.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=827460;file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro_telemetry\\plugin.py#243\u001b\\\u001b[2m243\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         the product. No personal data or IP addresses are stored on our side. To \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         opt out, set the `KEDRO_DISABLE_TELEMETRY` or `DO_NOT_TRACK` environment \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         variables, or create a `.telemetry` file in the current working          \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         directory with the contents `consent: false`. To hide this message,      \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         explicitly grant or deny consent. Read more at                           \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://docs.kedro.org/en/stable/configuration/telemetry.html\u001b[0m            \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys, tomllib\n",
    "from kedro.framework.project import configure_project\n",
    "from kedro.framework.session import KedroSession\n",
    "\n",
    "# Detecta raíz del proyecto y package_name\n",
    "project_path = Path.cwd() if (Path.cwd() / \"pyproject.toml\").exists() else Path.cwd().parent\n",
    "with open(project_path / \"pyproject.toml\", \"rb\") as f:\n",
    "    package_name = tomllib.load(f)[\"tool\"][\"kedro\"][\"package_name\"]\n",
    "\n",
    "# src importable + sesión\n",
    "sys.path.insert(0, str(project_path / \"src\"))\n",
    "configure_project(package_name)\n",
    "session = KedroSession.create(project_path=project_path)\n",
    "context = session.load_context()\n",
    "catalog = context.catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf27474b-d506-4f70-babb-14e0bed150a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/13/25 22:27:02] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #ff8700; text-decoration-color: #ff8700\">releases</span> <span style=\"font-weight: bold\">(</span>CSVDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                        <a href=\"file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py#1046\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1046</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/13/25 22:27:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[38;5;208mreleases\u001b[0m \u001b[1m(\u001b[0mCSVDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                        \u001b]8;id=237117;file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=338761;file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py#1046\u001b\\\u001b[2m1046\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/13/25 22:27:03] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #ff8700; text-decoration-color: #ff8700\">countries</span> <span style=\"font-weight: bold\">(</span>CSVDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                       <a href=\"file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py#1046\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1046</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/13/25 22:27:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[38;5;208mcountries\u001b[0m \u001b[1m(\u001b[0mCSVDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                       \u001b]8;id=959718;file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=45956;file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py#1046\u001b\\\u001b[2m1046\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #ff8700; text-decoration-color: #ff8700\">genres</span> <span style=\"font-weight: bold\">(</span>CSVDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                          <a href=\"file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py#1046\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1046</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[38;5;208mgenres\u001b[0m \u001b[1m(\u001b[0mCSVDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                          \u001b]8;id=227043;file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=823435;file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py#1046\u001b\\\u001b[2m1046\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset releases cargado\n",
      "dataset countries cargado\n",
      "dataset genres cargado\n"
     ]
    }
   ],
   "source": [
    "names = [\"releases\", \"countries\", \"genres\"]\n",
    "dfs = {name: catalog.load(name) for name in names}\n",
    "for name in names:\n",
    "    print(f\"dataset {name} cargado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1824911-1d0d-4bf5-824c-18f7d9b2e9b9",
   "metadata": {},
   "source": [
    "## Seleccionar los datos relevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc931c0-c00c-4b49-bf32-5c70fa46289c",
   "metadata": {},
   "source": [
    "### Datasets y columnas permitidas\n",
    "------------------------------\n",
    "\n",
    "*   **releases**: usar **id**, **date**_(excluir rating y type — no son necesarios y rating tiene alta ausencia)_\n",
    "    \n",
    "*   **countries**: usar **id**, **country**\n",
    "    \n",
    "*   **genres**: usar **id**, **genre**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eba4e7-4991-457d-ae4a-144ba6e51a4b",
   "metadata": {},
   "source": [
    "### Reglas de selección y filtros\n",
    "-------------------------------------------\n",
    "\n",
    "1.  **Normalizar país** en countries.country y **quedarse solo con películas asociadas a EE. UU.**Alias aceptados: _USA, US, United States, United States of America_ (minúsculas, sin puntos/comedas).\n",
    "    \n",
    "2.  **Parsear releases.date** y calcular la **primera fecha** por película (min(date) por id) para no contar re-estrenos múltiples.\n",
    "    \n",
    "3.  **Filtrar periodo** a **\\[2000-01-01, 2019-12-31\\]** usando la **primera fecha**.\n",
    "    \n",
    "4.  **Intersección de llaves**: conservar solo id que aparezcan en **los tres** datasets (garantiza integridad al unir).\n",
    "    \n",
    "5.  **Uniones necesarias**:\n",
    "    \n",
    "    *   us\\_ids (del paso 1) **∩** min\\_release\\_2000\\_2019 (pasos 2–3) → base de películas **EE. UU. y década válida**.\n",
    "        \n",
    "    *   Unir esa base con genres por id para obtener **(id, decade, genre)**.\n",
    "        \n",
    "6.  **Evitar sobreconteo por multi-etiqueta**: **deduplicar** por **(id, genre, decade)** (una película aporta 1 por género en su década).\n",
    "    \n",
    "7.  **Columnas finales (dataset analítico mínimo)**:**id**, **decade** ∈ {**2000s**, **2010s**}, **genre**._(Opcional, para auditoría: first\\_date)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f94303f-002f-4395-94e6-63374427211b",
   "metadata": {},
   "source": [
    "## Limpiar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02d29cb0-5bad-4a92-811a-15aac2bca8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limpieza OK.\n",
      "Fechas no parseables removidas: 0\n",
      "Shapes ⇒ releases: (1201917, 3), countries: (693476, 3), genres: (1046849, 2)\n"
     ]
    }
   ],
   "source": [
    "# Bloque 2 — Limpiar los datos (autosuficiente: crea df_* si no existen)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Asegura dataframes base (desde dfs o desde catalog)\n",
    "if 'df_releases' not in globals() or 'df_countries' not in globals() or 'df_genres' not in globals():\n",
    "    if 'dfs' in globals():\n",
    "        _releases  = dfs[\"releases\"]\n",
    "        _countries = dfs[\"countries\"]\n",
    "        _genres    = dfs[\"genres\"]\n",
    "    else:\n",
    "        # Si no tienes `dfs`, intenta cargar desde Kedro catalog (asegúrate de haber hecho el setup)\n",
    "        _releases  = catalog.load(\"releases\")\n",
    "        _countries = catalog.load(\"countries\")\n",
    "        _genres    = catalog.load(\"genres\")\n",
    "\n",
    "    df_releases  = _releases[[\"id\",\"date\"]].copy()\n",
    "    df_countries = _countries[[\"id\",\"country\"]].copy()\n",
    "    df_genres    = _genres[[\"id\",\"genre\"]].copy()\n",
    "\n",
    "# --- Limpieza solicitada (sin transformar más de lo necesario) ---\n",
    "def _norm_txt(s):\n",
    "    if pd.isna(s): \n",
    "        return \"\"\n",
    "    return str(s).lower().replace(\".\",\"\").replace(\",\",\"\").strip()\n",
    "\n",
    "# Normalizar país (texto) – no filtra aún\n",
    "df_countries[\"_country_norm\"] = df_countries[\"country\"].map(_norm_txt)\n",
    "\n",
    "# Parseo robusto de fecha (naive)\n",
    "df_releases[\"_date_parsed\"] = pd.to_datetime(\n",
    "    df_releases[\"date\"], errors=\"coerce\", utc=True\n",
    ").dt.tz_localize(None)\n",
    "\n",
    "# Drop de fechas no parseables\n",
    "_before = len(df_releases)\n",
    "df_releases = df_releases.dropna(subset=[\"_date_parsed\"])\n",
    "_after = len(df_releases)\n",
    "\n",
    "# Remueve outliers temporales extremos (muy fuera de rango razonable)\n",
    "df_releases = df_releases[df_releases[\"_date_parsed\"].dt.year.between(1900, 2025)]\n",
    "\n",
    "# Deduplicación exacta por claves lógicas\n",
    "df_countries = df_countries.drop_duplicates(subset=[\"id\",\"country\"])\n",
    "df_genres    = df_genres.drop_duplicates(subset=[\"id\",\"genre\"])\n",
    "df_releases  = df_releases.drop_duplicates(subset=[\"id\",\"date\"])\n",
    "\n",
    "print(\"Limpieza OK.\")\n",
    "print(f\"Fechas no parseables removidas: {_before - _after}\")\n",
    "print(f\"Shapes ⇒ releases: {df_releases.shape}, countries: {df_countries.shape}, genres: {df_genres.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad8255-c7b9-432d-8dd2-dd826533a195",
   "metadata": {},
   "source": [
    "*   **Asegura los DataFrames base** (df\\_releases, df\\_countries, df\\_genres): si no existen, los crea desde dfs (o desde catalog) y **selecciona solo las columnas relevantes**.\n",
    "    \n",
    "*   **Normaliza texto de países** (\\_country\\_norm): pasa a minúsculas y quita puntos/comas para manejar variantes como _USA/US/United States_ de forma consistente.\n",
    "    \n",
    "*   **Parsea fechas** en releases.date a datetime (naive) y **elimina filas no parseables**.\n",
    "    \n",
    "*   **Acota outliers temporales groseros** a un rango amplio razonable **\\[1900, 2025\\]** (sin aplicar aún el recorte analítico 2000–2019).\n",
    "    \n",
    "*   **Deduplica** por **claves lógicas** en cada tabla:\n",
    "    \n",
    "    *   releases: (id, date)\n",
    "        \n",
    "    *   countries: (id, country)\n",
    "        \n",
    "    *   genres: (id, genre)\n",
    "        \n",
    "*   **Informa** un resumen: cuántas fechas inválidas se removieron y los **shapes** resultantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e1b59-250e-4b0e-8aba-f44ccb381873",
   "metadata": {},
   "source": [
    "## Construir nuevas variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0b69b7b-a642-4415-b122-f2d41319a677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features creadas: first_date, first_year, decade (2000s/2010s/other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_date</th>\n",
       "      <th>first_year</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>2023-07-06</td>\n",
       "      <td>2023</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000002</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>2019</td>\n",
       "      <td>2010s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000003</td>\n",
       "      <td>2022-03-11</td>\n",
       "      <td>2022</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000004</td>\n",
       "      <td>1999-09-10</td>\n",
       "      <td>1999</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000005</td>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>2016</td>\n",
       "      <td>2010s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "        id first_date  first_year decade\n",
       "\u001b[1;36m0\u001b[0m  \u001b[1;36m1000001\u001b[0m \u001b[1;36m2023\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m06\u001b[0m        \u001b[1;36m2023\u001b[0m  other\n",
       "\u001b[1;36m1\u001b[0m  \u001b[1;36m1000002\u001b[0m \u001b[1;36m2019\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m21\u001b[0m        \u001b[1;36m2019\u001b[0m  2010s\n",
       "\u001b[1;36m2\u001b[0m  \u001b[1;36m1000003\u001b[0m \u001b[1;36m2022\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m11\u001b[0m        \u001b[1;36m2022\u001b[0m  other\n",
       "\u001b[1;36m3\u001b[0m  \u001b[1;36m1000004\u001b[0m \u001b[1;36m1999\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m10\u001b[0m        \u001b[1;36m1999\u001b[0m  other\n",
       "\u001b[1;36m4\u001b[0m  \u001b[1;36m1000005\u001b[0m \u001b[1;36m2016\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m31\u001b[0m        \u001b[1;36m2016\u001b[0m  2010s"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_release = (df_releases.groupby(\"id\", as_index=False)[\"_date_parsed\"].min()\n",
    "                           .rename(columns={\"_date_parsed\":\"first_date\"}))\n",
    "min_release[\"first_year\"] = min_release[\"first_date\"].dt.year\n",
    "min_release[\"decade\"] = np.where(min_release[\"first_year\"].between(2000, 2009), \"2000s\",\n",
    "                         np.where(min_release[\"first_year\"].between(2010, 2019), \"2010s\", \"other\"))\n",
    "\n",
    "print(\"Features creadas: first_date, first_year, decade (2000s/2010s/other)\")\n",
    "min_release.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f36c5-3534-47d7-837b-a5171f121ee7",
   "metadata": {},
   "source": [
    "El bloque calcula, para cada película, su **primera fecha de estreno** disponible y a partir de ella asigna una **década analítica**:\n",
    "    \n",
    "*   Obtiene la **fecha mínima** por id (la más antigua entre todos sus estrenos) y la llama first\\_date. Esto evita contar **reestrenos** múltiples.\n",
    "    \n",
    "*   Extrae el **año** de first\\_date como first\\_year.\n",
    "    \n",
    "*   Clasifica en **“2000s”** si el año está entre 2000–2009, en **“2010s”** si está entre 2010–2019 y en **“other”** si cae **antes de 2000** o **después de 2019**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcbeb50-4308-44a7-8340-f180b970e8b4",
   "metadata": {},
   "source": [
    "## Integración de datos de múltiples fuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "481d7712-c8f6-4122-ac88-3615e162bd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Integración completada ===\n",
      "Filas (id, decade, genre): 102060\n",
      "Décadas: ['2000s', '2010s']\n",
      "Géneros distintos: 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>decade</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000005</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000005</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000005</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000005</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000007</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Science Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "        id decade            genre\n",
       "\u001b[1;36m0\u001b[0m  \u001b[1;36m1000005\u001b[0m  2010s            Drama\n",
       "\u001b[1;36m1\u001b[0m  \u001b[1;36m1000005\u001b[0m  2010s           Comedy\n",
       "\u001b[1;36m2\u001b[0m  \u001b[1;36m1000005\u001b[0m  2010s            Music\n",
       "\u001b[1;36m3\u001b[0m  \u001b[1;36m1000005\u001b[0m  2010s          Romance\n",
       "\u001b[1;36m4\u001b[0m  \u001b[1;36m1000007\u001b[0m  2010s  Science Fiction"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identificar EE. UU. tras normalización\n",
    "US_ALIASES = {\"usa\",\"us\",\"u s\",\"u s a\",\"united states\",\"united states of america\"}\n",
    "df_countries[\"is_us\"] = df_countries[\"_country_norm\"].isin(US_ALIASES)\n",
    "us_ids = set(df_countries.loc[df_countries[\"is_us\"], \"id\"].unique())\n",
    "\n",
    "# Integridad básica de llaves\n",
    "ids_rel = set(df_releases[\"id\"].unique())\n",
    "ids_gen = set(df_genres[\"id\"].unique())\n",
    "ids_cty = set(df_countries[\"id\"].unique())\n",
    "ids_all = ids_rel & ids_gen & ids_cty\n",
    "\n",
    "# Base de películas: EE. UU. + décadas de interés (2000s/2010s)\n",
    "base = (min_release[min_release[\"decade\"].isin([\"2000s\",\"2010s\"])]\n",
    "        .loc[lambda d: d[\"id\"].isin(us_ids & ids_all), [\"id\",\"first_date\",\"decade\"]]\n",
    "        .drop_duplicates())\n",
    "\n",
    "# Unir con géneros (multi-etiqueta) y deduplicar\n",
    "final_df = (base.merge(df_genres[[\"id\",\"genre\"]], on=\"id\", how=\"inner\")\n",
    "                 .drop_duplicates(subset=[\"id\",\"genre\",\"decade\"])\n",
    "                 [[\"id\",\"decade\",\"genre\"]]\n",
    "                 .reset_index(drop=True))\n",
    "\n",
    "print(\"=== Integración completada ===\")\n",
    "print(\"Filas (id, decade, genre):\", final_df.shape[0])\n",
    "print(\"Décadas:\", sorted(final_df[\"decade\"].unique().tolist()))\n",
    "print(\"Géneros distintos:\", final_df[\"genre\"].nunique())\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0645d3-994b-46d6-acbb-9c620117e8ce",
   "metadata": {},
   "source": [
    "### Explicación del bloque (integración y filtrado final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7c28e7-30d9-42d2-9b52-f299d65a099b",
   "metadata": {},
   "source": [
    "1.  Identificar películas de EE. UU.\n",
    "    \n",
    "    *   Se parte de df\\_countries\\[\"\\_country\\_norm\"\\] (país normalizado) y se define un conjunto de alias de EE. UU. (USA, US, United States, etc.).\n",
    "        \n",
    "    *   Se marca cada fila con is\\_us y se extraen los **us\\_ids** (todos los id de películas asociadas a EE. UU.).\n",
    "        \n",
    "      Esto fija el universo de películas “de EE. UU.” para el análisis.\n",
    "        \n",
    "2.  Integridad referencial (llaves comunes).\n",
    "    \n",
    "    *   Se obtienen los conjuntos de id presentes en cada tabla: releases, genres, countries.\n",
    "        \n",
    "    *   Se calcula **ids\\_all** como la intersección de los tres (solo id que existen en **todas** las fuentes).\n",
    "        \n",
    "      Evita perder filas al unir después (joins más estables).\n",
    "        \n",
    "3.  Base temporal filtrada a las décadas de interés.\n",
    "    \n",
    "    *   Desde min\\_release (que ya tiene la **primera fecha** por película y la **década**), se filtra a **2000s** y **2010s**.\n",
    "        \n",
    "    *   Además, se restringe a id ∈ (us\\_ids ∩ ids\\_all).\n",
    "        \n",
    "    *   Se conserva \\[\"id\", \"first\\_date\", \"decade\"\\] y se eliminan duplicados.\n",
    "        \n",
    "      Queda una “base” con películas **de EE. UU.**, con **primera fecha** en 2000s/2010s y con presencia en las tres tablas.\n",
    "        \n",
    "4.  Unión con géneros y deduplicación analítica.\n",
    "    \n",
    "    *   Se hace un merge con df\\_genres\\[\\[\"id\",\"genre\"\\]\\] para obtener los **géneros** de cada película.\n",
    "        \n",
    "    *   Se **deduplica** por **(id, genre, decade)**: una película cuenta **una vez** por género en su década (evita sobreconteo por multi-etiqueta y reestrenos).\n",
    "        \n",
    "    *   Se dejan solo las columnas analíticas mínimas: **id, decade, genre**.\n",
    "        \n",
    "      El resultado es final\\_df, listo para conteos, participaciones y Top-3 por década."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b7f9d6-7f45-4f89-85e7-30a9856fef7e",
   "metadata": {},
   "source": [
    "### Formateo y transformación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caa56be5-7db8-42d5-9c2d-647a0848eb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados (id,genre,decade): OK (0)\n",
      "\n",
      "Dataset final listo para análisis del Top-3 por década.\n",
      "id           int64\n",
      "decade    category\n",
      "genre     category\n",
      "dtype: object\n",
      "Guardado: final_df_us_2000s_2010s.parquet\n"
     ]
    }
   ],
   "source": [
    "# Tipos y orden\n",
    "final_df[\"id\"] = final_df[\"id\"].astype(\"int64\")\n",
    "final_df[\"decade\"] = pd.Categorical(final_df[\"decade\"], categories=[\"2000s\",\"2010s\"], ordered=True)\n",
    "final_df[\"genre\"] = final_df[\"genre\"].astype(\"category\")\n",
    "\n",
    "final_df = final_df.sort_values([\"decade\",\"genre\",\"id\"]).reset_index(drop=True)\n",
    "\n",
    "# QA rápido\n",
    "assert final_df[\"id\"].isna().sum()==0, \"Hay id nulos\"\n",
    "assert final_df[\"genre\"].isna().sum()==0, \"Hay genre nulos\"\n",
    "assert set(final_df[\"decade\"].unique()) <= {\"2000s\",\"2010s\"}, \"Décadas fuera de rango\"\n",
    "dup_ok = final_df.duplicated(subset=[\"id\",\"genre\",\"decade\"]).sum()==0\n",
    "print(\"Duplicados (id,genre,decade):\", \"OK (0)\" if dup_ok else \"Hay duplicados\")\n",
    "\n",
    "print(\"\\nDataset final listo para análisis del Top-3 por década.\")\n",
    "print(final_df.dtypes)\n",
    "\n",
    "# Guardar versión limpia\n",
    "final_df.to_parquet(\"final_df_us_2000s_2010s.parquet\", index=False)\n",
    "print(\"Guardado: final_df_us_2000s_2010s.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501c37c1-9e71-4720-aae7-24638cd8922c",
   "metadata": {},
   "source": [
    "1.  **Tipado y orden canónico**\n",
    "    \n",
    "    *   id → int64: asegura identificadores numéricos consistentes.\n",
    "        \n",
    "    *   decade → **Categorical ordenada** con categorías \\[\"2000s\",\"2010s\"\\]: fija el orden lógico (útil para sort, groupby, gráficos).\n",
    "        \n",
    "    *   genre → **Categorical**: reduce memoria y acelera operaciones sobre texto repetido.\n",
    "        \n",
    "    *   Ordena el dataset por \\[\"decade\",\"genre\",\"id\"\\] y reinicia el índice para dejarlo limpio.\n",
    "        \n",
    "2.  **QA rápido (sanidad del dataset)**\n",
    "    \n",
    "    *   assert sin nulos en id y genre.\n",
    "        \n",
    "    *   assert que decade solo tenga valores esperados (2000s, 2010s).\n",
    "        \n",
    "    *   Verifica duplicados en la clave analítica **(id, genre, decade)** y reporta si hay (debería ser 0 tras la deduplicación previa).\n",
    "        \n",
    "3.  **Inspección y persistencia**\n",
    "    \n",
    "    *   Imprime los dtypes finales (para auditar el esquema).\n",
    "        \n",
    "    *   **Guarda** una versión **limpia y columnar** en **Parquet** (final\\_df\\_us\\_2000s\\_2010s.parquet), formato eficiente (compresión, esquema, lectura rápida) para los análisis posteriores del **Top-3 por década** y pruebas estadísticas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (letterboxdml)",
   "language": "python",
   "name": "letterboxdml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
