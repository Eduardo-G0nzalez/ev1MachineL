{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf39e9d-386a-43bd-ab4b-e5da48787830",
   "metadata": {},
   "source": [
    "# Fase 3: Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad18c9-3f27-4471-9e78-d86a35d13a7a",
   "metadata": {},
   "source": [
    "## Setup Kedro | Importación de librerías y carga de los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69f3a9d8-0a6b-4bb7-a8cf-227dd818eca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/13/25 22:26:59] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Kedro is sending anonymous usage data with the sole purpose of improving <a href=\"file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro_telemetry\\plugin.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">plugin.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro_telemetry\\plugin.py#243\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">243</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         the product. No personal data or IP addresses are stored on our side. To <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         opt out, set the `KEDRO_DISABLE_TELEMETRY` or `DO_NOT_TRACK` environment <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         variables, or create a `.telemetry` file in the current working          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         directory with the contents `consent: false`. To hide this message,      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         explicitly grant or deny consent. Read more at                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://docs.kedro.org/en/stable/configuration/telemetry.html</span>            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/13/25 22:26:59]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Kedro is sending anonymous usage data with the sole purpose of improving \u001b]8;id=438880;file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro_telemetry\\plugin.py\u001b\\\u001b[2mplugin.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=827460;file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro_telemetry\\plugin.py#243\u001b\\\u001b[2m243\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         the product. No personal data or IP addresses are stored on our side. To \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         opt out, set the `KEDRO_DISABLE_TELEMETRY` or `DO_NOT_TRACK` environment \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         variables, or create a `.telemetry` file in the current working          \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         directory with the contents `consent: false`. To hide this message,      \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         explicitly grant or deny consent. Read more at                           \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://docs.kedro.org/en/stable/configuration/telemetry.html\u001b[0m            \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys, tomllib\n",
    "from kedro.framework.project import configure_project\n",
    "from kedro.framework.session import KedroSession\n",
    "\n",
    "# Detecta raíz del proyecto y package_name\n",
    "project_path = Path.cwd() if (Path.cwd() / \"pyproject.toml\").exists() else Path.cwd().parent\n",
    "with open(project_path / \"pyproject.toml\", \"rb\") as f:\n",
    "    package_name = tomllib.load(f)[\"tool\"][\"kedro\"][\"package_name\"]\n",
    "\n",
    "# src importable + sesión\n",
    "sys.path.insert(0, str(project_path / \"src\"))\n",
    "configure_project(package_name)\n",
    "session = KedroSession.create(project_path=project_path)\n",
    "context = session.load_context()\n",
    "catalog = context.catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf27474b-d506-4f70-babb-14e0bed150a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/13/25 22:27:02] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #ff8700; text-decoration-color: #ff8700\">releases</span> <span style=\"font-weight: bold\">(</span>CSVDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                        <a href=\"file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py#1046\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1046</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/13/25 22:27:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[38;5;208mreleases\u001b[0m \u001b[1m(\u001b[0mCSVDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                        \u001b]8;id=237117;file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=338761;file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py#1046\u001b\\\u001b[2m1046\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/13/25 22:27:03] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #ff8700; text-decoration-color: #ff8700\">countries</span> <span style=\"font-weight: bold\">(</span>CSVDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                       <a href=\"file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py#1046\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1046</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/13/25 22:27:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[38;5;208mcountries\u001b[0m \u001b[1m(\u001b[0mCSVDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                       \u001b]8;id=959718;file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=45956;file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py#1046\u001b\\\u001b[2m1046\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #ff8700; text-decoration-color: #ff8700\">genres</span> <span style=\"font-weight: bold\">(</span>CSVDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                          <a href=\"file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py#1046\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1046</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[38;5;208mgenres\u001b[0m \u001b[1m(\u001b[0mCSVDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                          \u001b]8;id=227043;file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=823435;file://C:\\Users\\edugo\\Desktop\\Workspace\\Universidad\\2025-II\\MachineLearning\\letterboxdml\\.venv\\Lib\\site-packages\\kedro\\io\\data_catalog.py#1046\u001b\\\u001b[2m1046\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset releases cargado\n",
      "dataset countries cargado\n",
      "dataset genres cargado\n"
     ]
    }
   ],
   "source": [
    "names = [\"releases\", \"countries\", \"genres\"]\n",
    "dfs = {name: catalog.load(name) for name in names}\n",
    "for name in names:\n",
    "    print(f\"dataset {name} cargado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1824911-1d0d-4bf5-824c-18f7d9b2e9b9",
   "metadata": {},
   "source": [
    "## Seleccionar los datos relevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc931c0-c00c-4b49-bf32-5c70fa46289c",
   "metadata": {},
   "source": [
    "### Datasets y columnas permitidas\n",
    "------------------------------\n",
    "\n",
    "*   **releases**: usar **id**, **date**_(excluir rating y type — no son necesarios y rating tiene alta ausencia)_\n",
    "    \n",
    "*   **countries**: usar **id**, **country**\n",
    "    \n",
    "*   **genres**: usar **id**, **genre**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eba4e7-4991-457d-ae4a-144ba6e51a4b",
   "metadata": {},
   "source": [
    "### Reglas de selección y filtros\n",
    "-------------------------------------------\n",
    "\n",
    "1.  **Normalizar país** en countries.country y **quedarse solo con películas asociadas a EE. UU.**Alias aceptados: _USA, US, United States, United States of America_ (minúsculas, sin puntos/comedas).\n",
    "    \n",
    "2.  **Parsear releases.date** y calcular la **primera fecha** por película (min(date) por id) para no contar re-estrenos múltiples.\n",
    "    \n",
    "3.  **Filtrar periodo** a **\\[2000-01-01, 2019-12-31\\]** usando la **primera fecha**.\n",
    "    \n",
    "4.  **Intersección de llaves**: conservar solo id que aparezcan en **los tres** datasets (garantiza integridad al unir).\n",
    "    \n",
    "5.  **Uniones necesarias**:\n",
    "    \n",
    "    *   us\\_ids (del paso 1) **∩** min\\_release\\_2000\\_2019 (pasos 2–3) → base de películas **EE. UU. y década válida**.\n",
    "        \n",
    "    *   Unir esa base con genres por id para obtener **(id, decade, genre)**.\n",
    "        \n",
    "6.  **Evitar sobreconteo por multi-etiqueta**: **deduplicar** por **(id, genre, decade)** (una película aporta 1 por género en su década).\n",
    "    \n",
    "7.  **Columnas finales (dataset analítico mínimo)**:**id**, **decade** ∈ {**2000s**, **2010s**}, **genre**._(Opcional, para auditoría: first\\_date)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f94303f-002f-4395-94e6-63374427211b",
   "metadata": {},
   "source": [
    "## Limpiar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02d29cb0-5bad-4a92-811a-15aac2bca8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limpieza OK.\n",
      "Fechas no parseables removidas: 0\n",
      "Shapes ⇒ releases: (1201917, 3), countries: (693476, 3), genres: (1046849, 2)\n"
     ]
    }
   ],
   "source": [
    "# Bloque 2 — Limpiar los datos (autosuficiente: crea df_* si no existen)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Asegura dataframes base (desde dfs o desde catalog)\n",
    "if 'df_releases' not in globals() or 'df_countries' not in globals() or 'df_genres' not in globals():\n",
    "    if 'dfs' in globals():\n",
    "        _releases  = dfs[\"releases\"]\n",
    "        _countries = dfs[\"countries\"]\n",
    "        _genres    = dfs[\"genres\"]\n",
    "    else:\n",
    "        # Si no tienes `dfs`, intenta cargar desde Kedro catalog (asegúrate de haber hecho el setup)\n",
    "        _releases  = catalog.load(\"releases\")\n",
    "        _countries = catalog.load(\"countries\")\n",
    "        _genres    = catalog.load(\"genres\")\n",
    "\n",
    "    df_releases  = _releases[[\"id\",\"date\"]].copy()\n",
    "    df_countries = _countries[[\"id\",\"country\"]].copy()\n",
    "    df_genres    = _genres[[\"id\",\"genre\"]].copy()\n",
    "\n",
    "# --- Limpieza solicitada (sin transformar más de lo necesario) ---\n",
    "def _norm_txt(s):\n",
    "    if pd.isna(s): \n",
    "        return \"\"\n",
    "    return str(s).lower().replace(\".\",\"\").replace(\",\",\"\").strip()\n",
    "\n",
    "# Normalizar país (texto) – no filtra aún\n",
    "df_countries[\"_country_norm\"] = df_countries[\"country\"].map(_norm_txt)\n",
    "\n",
    "# Parseo robusto de fecha (naive)\n",
    "df_releases[\"_date_parsed\"] = pd.to_datetime(\n",
    "    df_releases[\"date\"], errors=\"coerce\", utc=True\n",
    ").dt.tz_localize(None)\n",
    "\n",
    "# Drop de fechas no parseables\n",
    "_before = len(df_releases)\n",
    "df_releases = df_releases.dropna(subset=[\"_date_parsed\"])\n",
    "_after = len(df_releases)\n",
    "\n",
    "# Remueve outliers temporales extremos (muy fuera de rango razonable)\n",
    "df_releases = df_releases[df_releases[\"_date_parsed\"].dt.year.between(1900, 2025)]\n",
    "\n",
    "# Deduplicación exacta por claves lógicas\n",
    "df_countries = df_countries.drop_duplicates(subset=[\"id\",\"country\"])\n",
    "df_genres    = df_genres.drop_duplicates(subset=[\"id\",\"genre\"])\n",
    "df_releases  = df_releases.drop_duplicates(subset=[\"id\",\"date\"])\n",
    "\n",
    "print(\"Limpieza OK.\")\n",
    "print(f\"Fechas no parseables removidas: {_before - _after}\")\n",
    "print(f\"Shapes ⇒ releases: {df_releases.shape}, countries: {df_countries.shape}, genres: {df_genres.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad8255-c7b9-432d-8dd2-dd826533a195",
   "metadata": {},
   "source": [
    "*   **Asegura los DataFrames base** (df\\_releases, df\\_countries, df\\_genres): si no existen, los crea desde dfs (o desde catalog) y **selecciona solo las columnas relevantes**.\n",
    "    \n",
    "*   **Normaliza texto de países** (\\_country\\_norm): pasa a minúsculas y quita puntos/comas para manejar variantes como _USA/US/United States_ de forma consistente.\n",
    "    \n",
    "*   **Parsea fechas** en releases.date a datetime (naive) y **elimina filas no parseables**.\n",
    "    \n",
    "*   **Acota outliers temporales groseros** a un rango amplio razonable **\\[1900, 2025\\]** (sin aplicar aún el recorte analítico 2000–2019).\n",
    "    \n",
    "*   **Deduplica** por **claves lógicas** en cada tabla:\n",
    "    \n",
    "    *   releases: (id, date)\n",
    "        \n",
    "    *   countries: (id, country)\n",
    "        \n",
    "    *   genres: (id, genre)\n",
    "        \n",
    "*   **Informa** un resumen: cuántas fechas inválidas se removieron y los **shapes** resultantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e1b59-250e-4b0e-8aba-f44ccb381873",
   "metadata": {},
   "source": [
    "## Construir nuevas variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0b69b7b-a642-4415-b122-f2d41319a677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features creadas: first_date, first_year, decade (2000s/2010s/other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_date</th>\n",
       "      <th>first_year</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>2023-07-06</td>\n",
       "      <td>2023</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000002</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>2019</td>\n",
       "      <td>2010s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000003</td>\n",
       "      <td>2022-03-11</td>\n",
       "      <td>2022</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000004</td>\n",
       "      <td>1999-09-10</td>\n",
       "      <td>1999</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000005</td>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>2016</td>\n",
       "      <td>2010s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "        id first_date  first_year decade\n",
       "\u001b[1;36m0\u001b[0m  \u001b[1;36m1000001\u001b[0m \u001b[1;36m2023\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m06\u001b[0m        \u001b[1;36m2023\u001b[0m  other\n",
       "\u001b[1;36m1\u001b[0m  \u001b[1;36m1000002\u001b[0m \u001b[1;36m2019\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m21\u001b[0m        \u001b[1;36m2019\u001b[0m  2010s\n",
       "\u001b[1;36m2\u001b[0m  \u001b[1;36m1000003\u001b[0m \u001b[1;36m2022\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m11\u001b[0m        \u001b[1;36m2022\u001b[0m  other\n",
       "\u001b[1;36m3\u001b[0m  \u001b[1;36m1000004\u001b[0m \u001b[1;36m1999\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m10\u001b[0m        \u001b[1;36m1999\u001b[0m  other\n",
       "\u001b[1;36m4\u001b[0m  \u001b[1;36m1000005\u001b[0m \u001b[1;36m2016\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m31\u001b[0m        \u001b[1;36m2016\u001b[0m  2010s"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_release = (df_releases.groupby(\"id\", as_index=False)[\"_date_parsed\"].min()\n",
    "                           .rename(columns={\"_date_parsed\":\"first_date\"}))\n",
    "min_release[\"first_year\"] = min_release[\"first_date\"].dt.year\n",
    "min_release[\"decade\"] = np.where(min_release[\"first_year\"].between(2000, 2009), \"2000s\",\n",
    "                         np.where(min_release[\"first_year\"].between(2010, 2019), \"2010s\", \"other\"))\n",
    "\n",
    "print(\"Features creadas: first_date, first_year, decade (2000s/2010s/other)\")\n",
    "min_release.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f36c5-3534-47d7-837b-a5171f121ee7",
   "metadata": {},
   "source": [
    "El bloque calcula, para cada película, su **primera fecha de estreno** disponible y a partir de ella asigna una **década analítica**:\n",
    "    \n",
    "*   Obtiene la **fecha mínima** por id (la más antigua entre todos sus estrenos) y la llama first\\_date. Esto evita contar **reestrenos** múltiples.\n",
    "    \n",
    "*   Extrae el **año** de first\\_date como first\\_year.\n",
    "    \n",
    "*   Clasifica en **“2000s”** si el año está entre 2000–2009, en **“2010s”** si está entre 2010–2019 y en **“other”** si cae **antes de 2000** o **después de 2019**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcbeb50-4308-44a7-8340-f180b970e8b4",
   "metadata": {},
   "source": [
    "## Integración de datos de múltiples fuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "481d7712-c8f6-4122-ac88-3615e162bd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Integración completada ===\n",
      "Filas (id, decade, genre): 102060\n",
      "Décadas: ['2000s', '2010s']\n",
      "Géneros distintos: 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>decade</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000005</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000005</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000005</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000005</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000007</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Science Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "        id decade            genre\n",
       "\u001b[1;36m0\u001b[0m  \u001b[1;36m1000005\u001b[0m  2010s            Drama\n",
       "\u001b[1;36m1\u001b[0m  \u001b[1;36m1000005\u001b[0m  2010s           Comedy\n",
       "\u001b[1;36m2\u001b[0m  \u001b[1;36m1000005\u001b[0m  2010s            Music\n",
       "\u001b[1;36m3\u001b[0m  \u001b[1;36m1000005\u001b[0m  2010s          Romance\n",
       "\u001b[1;36m4\u001b[0m  \u001b[1;36m1000007\u001b[0m  2010s  Science Fiction"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identificar EE. UU. tras normalización\n",
    "US_ALIASES = {\"usa\",\"us\",\"u s\",\"u s a\",\"united states\",\"united states of america\"}\n",
    "df_countries[\"is_us\"] = df_countries[\"_country_norm\"].isin(US_ALIASES)\n",
    "us_ids = set(df_countries.loc[df_countries[\"is_us\"], \"id\"].unique())\n",
    "\n",
    "# Integridad básica de llaves\n",
    "ids_rel = set(df_releases[\"id\"].unique())\n",
    "ids_gen = set(df_genres[\"id\"].unique())\n",
    "ids_cty = set(df_countries[\"id\"].unique())\n",
    "ids_all = ids_rel & ids_gen & ids_cty\n",
    "\n",
    "# Base de películas: EE. UU. + décadas de interés (2000s/2010s)\n",
    "base = (min_release[min_release[\"decade\"].isin([\"2000s\",\"2010s\"])]\n",
    "        .loc[lambda d: d[\"id\"].isin(us_ids & ids_all), [\"id\",\"first_date\",\"decade\"]]\n",
    "        .drop_duplicates())\n",
    "\n",
    "# Unir con géneros (multi-etiqueta) y deduplicar\n",
    "final_df = (base.merge(df_genres[[\"id\",\"genre\"]], on=\"id\", how=\"inner\")\n",
    "                 .drop_duplicates(subset=[\"id\",\"genre\",\"decade\"])\n",
    "                 [[\"id\",\"decade\",\"genre\"]]\n",
    "                 .reset_index(drop=True))\n",
    "\n",
    "print(\"=== Integración completada ===\")\n",
    "print(\"Filas (id, decade, genre):\", final_df.shape[0])\n",
    "print(\"Décadas:\", sorted(final_df[\"decade\"].unique().tolist()))\n",
    "print(\"Géneros distintos:\", final_df[\"genre\"].nunique())\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0645d3-994b-46d6-acbb-9c620117e8ce",
   "metadata": {},
   "source": [
    "### Explicación del bloque (integración y filtrado final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7c28e7-30d9-42d2-9b52-f299d65a099b",
   "metadata": {},
   "source": [
    "1.  Identificar películas de EE. UU.\n",
    "    \n",
    "    *   Se parte de df\\_countries\\[\"\\_country\\_norm\"\\] (país normalizado) y se define un conjunto de alias de EE. UU. (USA, US, United States, etc.).\n",
    "        \n",
    "    *   Se marca cada fila con is\\_us y se extraen los **us\\_ids** (todos los id de películas asociadas a EE. UU.).\n",
    "        \n",
    "      Esto fija el universo de películas “de EE. UU.” para el análisis.\n",
    "        \n",
    "2.  Integridad referencial (llaves comunes).\n",
    "    \n",
    "    *   Se obtienen los conjuntos de id presentes en cada tabla: releases, genres, countries.\n",
    "        \n",
    "    *   Se calcula **ids\\_all** como la intersección de los tres (solo id que existen en **todas** las fuentes).\n",
    "        \n",
    "      Evita perder filas al unir después (joins más estables).\n",
    "        \n",
    "3.  Base temporal filtrada a las décadas de interés.\n",
    "    \n",
    "    *   Desde min\\_release (que ya tiene la **primera fecha** por película y la **década**), se filtra a **2000s** y **2010s**.\n",
    "        \n",
    "    *   Además, se restringe a id ∈ (us\\_ids ∩ ids\\_all).\n",
    "        \n",
    "    *   Se conserva \\[\"id\", \"first\\_date\", \"decade\"\\] y se eliminan duplicados.\n",
    "        \n",
    "      Queda una “base” con películas **de EE. UU.**, con **primera fecha** en 2000s/2010s y con presencia en las tres tablas.\n",
    "        \n",
    "4.  Unión con géneros y deduplicación analítica.\n",
    "    \n",
    "    *   Se hace un merge con df\\_genres\\[\\[\"id\",\"genre\"\\]\\] para obtener los **géneros** de cada película.\n",
    "        \n",
    "    *   Se **deduplica** por **(id, genre, decade)**: una película cuenta **una vez** por género en su década (evita sobreconteo por multi-etiqueta y reestrenos).\n",
    "        \n",
    "    *   Se dejan solo las columnas analíticas mínimas: **id, decade, genre**.\n",
    "        \n",
    "      El resultado es final\\_df, listo para conteos, participaciones y Top-3 por década."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b7f9d6-7f45-4f89-85e7-30a9856fef7e",
   "metadata": {},
   "source": [
    "### Formateo y transformación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caa56be5-7db8-42d5-9c2d-647a0848eb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados (id,genre,decade): OK (0)\n",
      "\n",
      "Dataset final listo para análisis del Top-3 por década.\n",
      "id           int64\n",
      "decade    category\n",
      "genre     category\n",
      "dtype: object\n",
      "Guardado: final_df_us_2000s_2010s.parquet\n"
     ]
    }
   ],
   "source": [
    "# Tipos y orden\n",
    "final_df[\"id\"] = final_df[\"id\"].astype(\"int64\")\n",
    "final_df[\"decade\"] = pd.Categorical(final_df[\"decade\"], categories=[\"2000s\",\"2010s\"], ordered=True)\n",
    "final_df[\"genre\"] = final_df[\"genre\"].astype(\"category\")\n",
    "\n",
    "final_df = final_df.sort_values([\"decade\",\"genre\",\"id\"]).reset_index(drop=True)\n",
    "\n",
    "# QA rápido\n",
    "assert final_df[\"id\"].isna().sum()==0, \"Hay id nulos\"\n",
    "assert final_df[\"genre\"].isna().sum()==0, \"Hay genre nulos\"\n",
    "assert set(final_df[\"decade\"].unique()) <= {\"2000s\",\"2010s\"}, \"Décadas fuera de rango\"\n",
    "dup_ok = final_df.duplicated(subset=[\"id\",\"genre\",\"decade\"]).sum()==0\n",
    "print(\"Duplicados (id,genre,decade):\", \"OK (0)\" if dup_ok else \"Hay duplicados\")\n",
    "\n",
    "print(\"\\nDataset final listo para análisis del Top-3 por década.\")\n",
    "print(final_df.dtypes)\n",
    "\n",
    "# Guardar versión limpia\n",
    "final_df.to_parquet(\"final_df_us_2000s_2010s.parquet\", index=False)\n",
    "print(\"Guardado: final_df_us_2000s_2010s.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e09039d",
   "metadata": {},
   "source": [
    "## Visualizaciones del Proceso de Limpieza y Transformación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f197aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaciones del proceso de limpieza y transformación\n",
    "# Esta sección documenta visualmente el impacto de cada paso de limpieza\n",
    "# y transformación de datos, mostrando antes/después de cada proceso\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configuración de gráficos\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (16, 12)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Crear figura con subplots para mostrar el proceso de limpieza\n",
    "# 6 gráficos que documentan diferentes aspectos del proceso de limpieza\n",
    "fig, axes = plt.subplots(3, 2, figsize=(20, 18))\n",
    "fig.suptitle('Proceso de Limpieza y Transformación de Datos', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Antes y después de la limpieza - Conteo de registros\n",
    "# Muestra el impacto cuantitativo de la limpieza de datos\n",
    "# La diferencia entre barras rojas (original) y verdes (limpio) indica registros removidos\n",
    "datasets_info = {\n",
    "    'Original': {\n",
    "        'releases': len(dfs['releases']),\n",
    "        'countries': len(dfs['countries']),\n",
    "        'genres': len(dfs['genres'])\n",
    "    },\n",
    "    'Después de Limpieza': {\n",
    "        'releases': len(df_releases),\n",
    "        'countries': len(df_countries),\n",
    "        'genres': len(df_genres)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Crear DataFrame para visualización\n",
    "comparison_data = []\n",
    "for stage, datasets in datasets_info.items():\n",
    "    for dataset, count in datasets.items():\n",
    "        comparison_data.append({'Etapa': stage, 'Dataset': dataset, 'Registros': count})\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_pivot = comparison_df.pivot(index='Dataset', columns='Etapa', values='Registros')\n",
    "\n",
    "# Gráfico de barras comparativo\n",
    "# Rojo = datos originales, Verde = datos después de limpieza\n",
    "x = np.arange(len(comparison_pivot.index))\n",
    "width = 0.35\n",
    "\n",
    "axes[0,0].bar(x - width/2, comparison_pivot['Original'], width, label='Original', alpha=0.7, color='lightcoral')\n",
    "axes[0,0].bar(x + width/2, comparison_pivot['Después de Limpieza'], width, label='Después de Limpieza', alpha=0.7, color='lightgreen')\n",
    "axes[0,0].set_title('Conteo de Registros: Antes vs Después de Limpieza')\n",
    "axes[0,0].set_ylabel('Número de Registros')\n",
    "axes[0,0].set_xticks(x)\n",
    "axes[0,0].set_xticklabels(comparison_pivot.index)\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Agregar valores numéricos en las barras para precisión\n",
    "for i, (orig, clean) in enumerate(zip(comparison_pivot['Original'], comparison_pivot['Después de Limpieza'])):\n",
    "    axes[0,0].text(i - width/2, orig + 50000, f'{orig:,}', ha='center', fontsize=9)\n",
    "    axes[0,0].text(i + width/2, clean + 50000, f'{clean:,}', ha='center', fontsize=9)\n",
    "\n",
    "# 2. Análisis de fechas - Distribución temporal antes y después del filtrado\n",
    "# Compara la distribución temporal de estrenos antes y después de la limpieza\n",
    "# Muestra cómo el filtrado temporal afecta la distribución de datos\n",
    "releases_original = dfs['releases'].copy()\n",
    "releases_original['date_parsed'] = pd.to_datetime(releases_original['date'], errors='coerce')\n",
    "releases_original = releases_original.dropna(subset=['date_parsed'])\n",
    "releases_original['year'] = releases_original['date_parsed'].dt.year\n",
    "\n",
    "# Filtrar años razonables para visualización\n",
    "releases_original = releases_original[(releases_original['year'] >= 1900) & (releases_original['year'] <= 2025)]\n",
    "\n",
    "# Datos después de la limpieza (ya procesados)\n",
    "releases_clean = df_releases.copy()\n",
    "releases_clean['year'] = releases_clean['_date_parsed'].dt.year\n",
    "\n",
    "# Crear histogramas comparativos superpuestos\n",
    "# Rojo = distribución original, Verde = distribución después de limpieza\n",
    "axes[0,1].hist(releases_original['year'], bins=50, alpha=0.6, label='Original', color='lightcoral', edgecolor='black')\n",
    "axes[0,1].hist(releases_clean['year'], bins=50, alpha=0.6, label='Después de Limpieza', color='lightgreen', edgecolor='black')\n",
    "axes[0,1].set_title('Distribución Temporal: Antes vs Después de Limpieza')\n",
    "axes[0,1].set_xlabel('Año')\n",
    "axes[0,1].set_ylabel('Frecuencia')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Análisis de normalización de países - Variantes de USA\n",
    "# Muestra las diferentes formas en que aparece \"Estados Unidos\" en los datos\n",
    "# Importante para entender la necesidad de normalización de países\n",
    "us_variants = df_countries[df_countries['is_us']]['country'].value_counts()\n",
    "axes[1,0].pie(us_variants.values, labels=us_variants.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[1,0].set_title('Variantes de Estados Unidos Detectadas')\n",
    "\n",
    "# 4. Distribución de décadas después del filtrado temporal\n",
    "# Muestra cómo quedan distribuidas las películas por década tras el filtrado\n",
    "# Azul = 2000s, Rojo = 2010s, Gris = otras décadas (si las hay)\n",
    "decade_counts = min_release['decade'].value_counts()\n",
    "colors = ['lightblue', 'lightcoral', 'lightgray']\n",
    "axes[1,1].bar(decade_counts.index, decade_counts.values, color=colors[:len(decade_counts)], alpha=0.7)\n",
    "axes[1,1].set_title('Distribución de Películas por Década (Después del Filtrado)')\n",
    "axes[1,1].set_ylabel('Número de Películas')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Agregar valores numéricos en las barras\n",
    "for i, v in enumerate(decade_counts.values):\n",
    "    axes[1,1].text(i, v + 1000, f'{v:,}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 5. Análisis de duplicados removidos\n",
    "# Calcular duplicados en cada dataset\n",
    "duplicates_info = {\n",
    "    'releases': len(dfs['releases']) - len(dfs['releases'].drop_duplicates(subset=['id', 'date'])),\n",
    "    'countries': len(dfs['countries']) - len(dfs['countries'].drop_duplicates(subset=['id', 'country'])),\n",
    "    'genres': len(dfs['genres']) - len(dfs['genres'].drop_duplicates(subset=['id', 'genre']))\n",
    "}\n",
    "\n",
    "duplicates_df = pd.DataFrame(list(duplicates_info.items()), columns=['Dataset', 'Duplicados_Removidos'])\n",
    "axes[2,0].bar(duplicates_df['Dataset'], duplicates_df['Duplicados_Removidos'], color='orange', alpha=0.7)\n",
    "axes[2,0].set_title('Duplicados Removidos por Dataset')\n",
    "axes[2,0].set_ylabel('Número de Duplicados')\n",
    "axes[2,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for i, v in enumerate(duplicates_df['Duplicados_Removidos']):\n",
    "    axes[2,0].text(i, v + 1000, f'{v:,}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 6. Resumen de la integración final\n",
    "integration_stats = {\n",
    "    'Películas EE.UU.': len(us_ids),\n",
    "    'Películas en 2000s/2010s': len(min_release[min_release['decade'].isin(['2000s', '2010s'])]),\n",
    "    'Películas Finales': len(final_df['id'].unique()),\n",
    "    'Géneros Únicos': final_df['genre'].nunique(),\n",
    "    'Registros Finales': len(final_df)\n",
    "}\n",
    "\n",
    "stats_df = pd.DataFrame(list(integration_stats.items()), columns=['Métrica', 'Valor'])\n",
    "axes[2,1].barh(stats_df['Métrica'], stats_df['Valor'], color='lightblue', alpha=0.7)\n",
    "axes[2,1].set_title('Estadísticas de Integración Final')\n",
    "axes[2,1].set_xlabel('Valor')\n",
    "axes[2,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for i, v in enumerate(stats_df['Valor']):\n",
    "    axes[2,1].text(v + 1000, i, f'{v:,}', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Resumen estadístico del proceso\n",
    "print(\"=== RESUMEN DEL PROCESO DE LIMPIEZA ===\")\n",
    "print(f\"Registros originales removidos: {len(dfs['releases']) - len(df_releases):,}\")\n",
    "print(f\"Duplicados removidos en releases: {duplicates_info['releases']:,}\")\n",
    "print(f\"Duplicados removidos en countries: {duplicates_info['countries']:,}\")\n",
    "print(f\"Duplicados removidos en genres: {duplicates_info['genres']:,}\")\n",
    "print(f\"Variantes de USA detectadas: {len(us_variants)}\")\n",
    "print(f\"Películas de EE.UU. identificadas: {len(us_ids):,}\")\n",
    "print(f\"Películas en décadas objetivo (2000s/2010s): {len(min_release[min_release['decade'].isin(['2000s', '2010s'])]):,}\")\n",
    "print(f\"Dataset final: {len(final_df):,} registros, {len(final_df['id'].unique()):,} películas únicas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc31a3bc",
   "metadata": {},
   "source": [
    "## Análisis Comparativo por Década (2000s vs 2010s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31b2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis comparativo detallado entre décadas 2000s y 2010s\n",
    "# Esta sección compara directamente las dos décadas objetivo del análisis\n",
    "# para identificar cambios en tendencias, géneros populares y patrones cinematográficos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configuración de gráficos\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (18, 12)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Preparar datos para análisis comparativo\n",
    "# Separamos los datos por década para comparaciones directas\n",
    "decade_2000s = final_df[final_df['decade'] == '2000s']\n",
    "decade_2010s = final_df[final_df['decade'] == '2010s']\n",
    "\n",
    "# Crear figura con subplots para análisis comparativo\n",
    "# 6 gráficos que exploran diferentes aspectos de la comparación entre décadas\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle('Análisis Comparativo: Década 2000s vs 2010s', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Conteo de películas por década\n",
    "# Compara el volumen total de películas entre las dos décadas\n",
    "# Azul = 2000s, Rojo = 2010s\n",
    "decade_counts = final_df['decade'].value_counts()\n",
    "colors = ['lightblue', 'lightcoral']\n",
    "bars = axes[0,0].bar(decade_counts.index, decade_counts.values, color=colors, alpha=0.7)\n",
    "axes[0,0].set_title('Número de Películas por Década')\n",
    "axes[0,0].set_ylabel('Número de Películas')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Agregar valores numéricos en las barras\n",
    "for i, v in enumerate(decade_counts.values):\n",
    "    axes[0,0].text(i, v + 500, f'{v:,}', ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 2. Top 10 géneros por década - Comparación lado a lado\n",
    "# Compara directamente los géneros más populares de cada década\n",
    "# Permite identificar cambios en las preferencias cinematográficas\n",
    "top_genres_2000s = decade_2000s['genre'].value_counts().head(10)\n",
    "top_genres_2010s = decade_2010s['genre'].value_counts().head(10)\n",
    "\n",
    "# Crear DataFrame para comparación\n",
    "comparison_genres = pd.DataFrame({\n",
    "    '2000s': top_genres_2000s,\n",
    "    '2010s': top_genres_2010s\n",
    "}).fillna(0)\n",
    "\n",
    "# Gráfico de barras horizontal lado a lado\n",
    "# Azul = 2000s, Rojo = 2010s\n",
    "x = np.arange(len(comparison_genres.index))\n",
    "width = 0.35\n",
    "\n",
    "axes[0,1].barh(x - width/2, comparison_genres['2000s'], width, label='2000s', alpha=0.7, color='lightblue')\n",
    "axes[0,1].barh(x + width/2, comparison_genres['2010s'], width, label='2010s', alpha=0.7, color='lightcoral')\n",
    "axes[0,1].set_title('Top 10 Géneros por Década')\n",
    "axes[0,1].set_xlabel('Número de Películas')\n",
    "axes[0,1].set_yticks(x)\n",
    "axes[0,1].set_yticklabels(comparison_genres.index)\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Distribución de géneros - Gráfico de pastel comparativo\n",
    "# Top 5 géneros para cada década\n",
    "top5_2000s = decade_2000s['genre'].value_counts().head(5)\n",
    "top5_2010s = decade_2010s['genre'].value_counts().head(5)\n",
    "\n",
    "# Crear subplots para pasteles\n",
    "ax1 = axes[0,2]\n",
    "ax2 = axes[1,0]\n",
    "\n",
    "# Pastel para 2000s\n",
    "wedges1, texts1, autotexts1 = ax1.pie(top5_2000s.values, labels=top5_2000s.index, autopct='%1.1f%%', \n",
    "                                       startangle=90, colors=plt.cm.Blues(np.linspace(0.3, 0.8, len(top5_2000s))))\n",
    "ax1.set_title('Top 5 Géneros - Década 2000s')\n",
    "\n",
    "# Pastel para 2010s\n",
    "wedges2, texts2, autotexts2 = ax2.pie(top5_2010s.values, labels=top5_2010s.index, autopct='%1.1f%%', \n",
    "                                       startangle=90, colors=plt.cm.Reds(np.linspace(0.3, 0.8, len(top5_2010s))))\n",
    "ax2.set_title('Top 5 Géneros - Década 2010s')\n",
    "\n",
    "# 4. Cambio en popularidad de géneros (2000s vs 2010s)\n",
    "# Calcula el cambio porcentual en popularidad de cada género entre décadas\n",
    "# Verde = crecimiento, Rojo = declive\n",
    "all_genres = set(decade_2000s['genre'].unique()) | set(decade_2010s['genre'].unique())\n",
    "genre_changes = []\n",
    "\n",
    "for genre in all_genres:\n",
    "    count_2000s = len(decade_2000s[decade_2000s['genre'] == genre])\n",
    "    count_2010s = len(decade_2010s[decade_2010s['genre'] == genre])\n",
    "    \n",
    "    if count_2000s > 0:\n",
    "        change_pct = ((count_2010s - count_2000s) / count_2000s) * 100\n",
    "    else:\n",
    "        change_pct = 100 if count_2010s > 0 else 0\n",
    "    \n",
    "    genre_changes.append({\n",
    "        'genre': genre,\n",
    "        'count_2000s': count_2000s,\n",
    "        'count_2010s': count_2010s,\n",
    "        'change_pct': change_pct\n",
    "    })\n",
    "\n",
    "changes_df = pd.DataFrame(genre_changes)\n",
    "changes_df = changes_df.sort_values('change_pct', ascending=False)\n",
    "\n",
    "# Top 10 géneros con mayor cambio (crecimiento o declive)\n",
    "top_changes = changes_df.head(10)\n",
    "colors = ['green' if x > 0 else 'red' for x in top_changes['change_pct']]\n",
    "\n",
    "bars = axes[1,1].barh(range(len(top_changes)), top_changes['change_pct'], color=colors, alpha=0.7)\n",
    "axes[1,1].set_title('Top 10 Géneros con Mayor Cambio (2000s → 2010s)')\n",
    "axes[1,1].set_xlabel('Cambio Porcentual (%)')\n",
    "axes[1,1].set_yticks(range(len(top_changes)))\n",
    "axes[1,1].set_yticklabels(top_changes['genre'])\n",
    "axes[1,1].axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Agregar valores porcentuales en las barras\n",
    "for i, v in enumerate(top_changes['change_pct']):\n",
    "    axes[1,1].text(v + (5 if v > 0 else -5), i, f'{v:.1f}%', va='center', \n",
    "                   ha='left' if v > 0 else 'right', fontsize=9)\n",
    "\n",
    "# 5. Distribución de géneros por película por década\n",
    "movies_2000s = decade_2000s.groupby('id').size()\n",
    "movies_2010s = decade_2010s.groupby('id').size()\n",
    "\n",
    "# Crear histogramas comparativos\n",
    "axes[1,2].hist([movies_2000s.values, movies_2010s.values], bins=15, alpha=0.6, \n",
    "               label=['2000s', '2010s'], color=['lightblue', 'lightcoral'], edgecolor='black')\n",
    "axes[1,2].set_title('Distribución de Géneros por Película')\n",
    "axes[1,2].set_xlabel('Número de Géneros por Película')\n",
    "axes[1,2].set_ylabel('Número de Películas')\n",
    "axes[1,2].legend()\n",
    "axes[1,2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estadísticas comparativas detalladas\n",
    "print(\"=== ANÁLISIS COMPARATIVO DETALLADO ===\")\n",
    "print(f\"\\nPELÍCULAS:\")\n",
    "print(f\"2000s: {len(decade_2000s['id'].unique()):,} películas\")\n",
    "print(f\"2010s: {len(decade_2010s['id'].unique()):,} películas\")\n",
    "print(f\"Crecimiento: {((len(decade_2010s['id'].unique()) - len(decade_2000s['id'].unique())) / len(decade_2000s['id'].unique()) * 100):.1f}%\")\n",
    "\n",
    "print(f\"\\nGÉNEROS:\")\n",
    "print(f\"Géneros únicos en 2000s: {decade_2000s['genre'].nunique()}\")\n",
    "print(f\"Géneros únicos en 2010s: {decade_2010s['genre'].nunique()}\")\n",
    "\n",
    "print(f\"\\nGÉNEROS MÁS POPULARES:\")\n",
    "print(\"2000s:\", list(top_genres_2000s.head(3).index))\n",
    "print(\"2010s:\", list(top_genres_2010s.head(3).index))\n",
    "\n",
    "print(f\"\\nGÉNEROS CON MAYOR CRECIMIENTO:\")\n",
    "top_growth = changes_df.head(3)\n",
    "for _, row in top_growth.iterrows():\n",
    "    print(f\"{row['genre']}: {row['change_pct']:.1f}% ({row['count_2000s']} → {row['count_2010s']})\")\n",
    "\n",
    "print(f\"\\nGÉNEROS CON MAYOR DECLIVE:\")\n",
    "top_decline = changes_df.tail(3)\n",
    "for _, row in top_decline.iterrows():\n",
    "    print(f\"{row['genre']}: {row['change_pct']:.1f}% ({row['count_2000s']} → {row['count_2010s']})\")\n",
    "\n",
    "print(f\"\\nGÉNEROS POR PELÍCULA (PROMEDIO):\")\n",
    "print(f\"2000s: {movies_2000s.mean():.2f} géneros por película\")\n",
    "print(f\"2010s: {movies_2010s.mean():.2f} géneros por película\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501c37c1-9e71-4720-aae7-24638cd8922c",
   "metadata": {},
   "source": [
    "1.  **Tipado y orden canónico**\n",
    "    \n",
    "    *   id → int64: asegura identificadores numéricos consistentes.\n",
    "        \n",
    "    *   decade → **Categorical ordenada** con categorías \\[\"2000s\",\"2010s\"\\]: fija el orden lógico (útil para sort, groupby, gráficos).\n",
    "        \n",
    "    *   genre → **Categorical**: reduce memoria y acelera operaciones sobre texto repetido.\n",
    "        \n",
    "    *   Ordena el dataset por \\[\"decade\",\"genre\",\"id\"\\] y reinicia el índice para dejarlo limpio.\n",
    "        \n",
    "2.  **QA rápido (sanidad del dataset)**\n",
    "    \n",
    "    *   assert sin nulos en id y genre.\n",
    "        \n",
    "    *   assert que decade solo tenga valores esperados (2000s, 2010s).\n",
    "        \n",
    "    *   Verifica duplicados en la clave analítica **(id, genre, decade)** y reporta si hay (debería ser 0 tras la deduplicación previa).\n",
    "        \n",
    "3.  **Inspección y persistencia**\n",
    "    \n",
    "    *   Imprime los dtypes finales (para auditar el esquema).\n",
    "        \n",
    "    *   **Guarda** una versión **limpia y columnar** en **Parquet** (final\\_df\\_us\\_2000s\\_2010s.parquet), formato eficiente (compresión, esquema, lectura rápida) para los análisis posteriores del **Top-3 por década** y pruebas estadísticas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (letterboxdml)",
   "language": "python",
   "name": "letterboxdml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
