# üöÄ Gu√≠a Completa de Ejecuci√≥n del Proyecto

## üìã √çndice
1. [¬øQu√© es DVC y para qu√© sirve?](#qu√©-es-dvc)
2. [Requisitos Previos](#requisitos-previos)
3. [Paso 1: Preparar el Entorno](#paso-1-preparar-el-entorno)
4. [Paso 2: Ejecutar con Docker y Airflow](#paso-2-ejecutar-con-docker-y-airflow)
5. [Paso 3: Ver Resultados en Airflow](#paso-3-ver-resultados-en-airflow)
6. [Paso 4: Usar DVC para Versionado](#paso-4-usar-dvc-para-versionado)
7. [Paso 5: Ver Resultados Finales](#paso-5-ver-resultados-finales)
8. [Troubleshooting](#troubleshooting)

---

## üîç ¬øQu√© es DVC y para qu√© sirve?

**DVC (Data Version Control)** es como Git pero para datos y modelos.

### ¬øPor qu√© usar DVC?
- ‚úÖ **Versionado de datos**: Guarda versiones de datasets grandes sin ocupar espacio en Git
- ‚úÖ **Reproducibilidad**: Puedes reproducir exactamente los mismos resultados
- ‚úÖ **M√©tricas versionadas**: Guarda las m√©tricas de cada experimento
- ‚úÖ **Colaboraci√≥n**: Compartir datasets y modelos sin problemas de tama√±o

### ¬øC√≥mo funciona?
1. DVC guarda los datos en almacenamiento remoto (o local)
2. Git solo guarda referencias peque√±as (archivos `.dvc`)
3. Cuando alguien clona el proyecto, puede descargar los datos con `dvc pull`

**En este proyecto, DVC versiona:**
- Datasets procesados (`data/02_intermediate/`, `data/03_primary/`)
- Datasets para ML (`data/05_model_input/`)
- Modelos entrenados (`data/06_models/`)
- M√©tricas de evaluaci√≥n (JSON con resultados)

---

## üì¶ Requisitos Previos

### Software necesario:
- ‚úÖ **Docker Desktop** instalado y ejecut√°ndose
- ‚úÖ **Git** (para versionado de c√≥digo)
- ‚úÖ **DVC** (opcional, para versionado de datos)

### Verificar instalaciones:
```bash
# Verificar Docker
docker --version
docker-compose --version

# Verificar Git
git --version

# Verificar DVC (si ya est√° instalado)
dvc --version
```

### üì¶ Instalaci√≥n de DVC

**Tienes 3 opciones:**

#### Opci√≥n 1: Instalaci√≥n Global (Recomendada para empezar) ‚≠ê
```bash
# Instalar DVC globalmente en tu computadora
pip install dvc

# Verificar instalaci√≥n
dvc --version
```
‚úÖ **Ventajas**: Simple, disponible en cualquier proyecto  
‚ö†Ô∏è **Desventajas**: Puede causar conflictos de versiones entre proyectos

#### Opci√≥n 2: Instalaci√≥n en el Proyecto (Mejor pr√°ctica)
```bash
# Crear entorno virtual (recomendado)
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Instalar DVC solo en este proyecto
pip install dvc

# O agregar a requirements.txt y luego:
pip install -r requirements.txt
```
‚úÖ **Ventajas**: A√≠sla dependencias, no afecta otros proyectos  
‚úÖ **Mejor para**: Proyectos que compartir√°s o producci√≥n

#### Opci√≥n 3: Solo usar DVC en Docker (No instalar localmente)
Si solo ejecutas con Docker, **NO necesitas instalar DVC localmente**.  
El Dockerfile ya puede incluirlo si lo agregas a `requirements.txt`.

---

## üõ†Ô∏è Paso 1: Preparar el Entorno

### 1.1. Navegar al directorio del proyecto
```bash
cd "C:\Users\mathi\OneDrive\Escritorio\Proyecto kedro\ev1MachineL"
```

### 1.2. Verificar que los datos existen
```bash
# Verificar que los datos raw est√°n presentes
dir data\01_raw\
```

Debes ver:
- `movies.csv`
- `releases.csv`
- `genres.csv`
- `countries.csv`

### 1.3. (Opcional) Inicializar DVC si es la primera vez
```bash
# Solo si es la primera vez que usas DVC en este proyecto
dvc init

# Configurar almacenamiento remoto (opcional)
# dvc remote add -d myremote /path/to/storage
```

---

## üê≥ Paso 2: Ejecutar con Docker y Airflow

### 2.1. Construir la imagen Docker (solo la primera vez o despu√©s de cambios)
```bash
# Construir imagen del proyecto
docker build -t kedro-ml .
```

‚è±Ô∏è **Tiempo estimado**: 5-10 minutos (solo la primera vez)

### 2.2. Iniciar todos los servicios (Docker Compose)
```bash
# Iniciar Airflow + Postgres + Pipeline Kedro
docker-compose up -d
```

Esto iniciar√°:
- üóÑÔ∏è **Postgres**: Base de datos para Airflow
- üîÑ **Airflow-init**: Inicializa Airflow (solo una vez)
- üåê **Airflow-webserver**: Interfaz web (puerto 8080)
- ‚öôÔ∏è **Airflow-scheduler**: Ejecuta los DAGs (IMPORTANTE: sin esto los DAGs no se ejecutan)
- üöÄ **Kedro-pipeline**: Ejecuta el pipeline autom√°ticamente

‚è±Ô∏è **Tiempo estimado**: 2-3 minutos para iniciar

### 2.3. Verificar que todo est√° corriendo
```bash
# Ver estado de los contenedores
docker-compose ps
```

Debes ver todos los servicios como **Up**:
```
NAME                   STATUS
airflow-init           Exited (0)
airflow-webserver      Up
airflow-scheduler      Up  ‚¨ÖÔ∏è IMPORTANTE: Sin esto los DAGs no ejecutan
postgres               Up
ml-letterboxd-pipeline Up
```

**‚ö†Ô∏è Si no ves `airflow-scheduler` en la lista, los DAGs NO se ejecutar√°n aunque los actives.**

### 2.4. Ver logs (opcional)

**‚ö†Ô∏è Importante**: El comando `logs -f` NO termina solo. Muestra logs en tiempo real hasta que presiones `Ctrl + C`.

```bash
# Ver logs que TERMINAN (√∫ltimos 100 l√≠neas)
docker-compose logs --tail=100

# Ver logs que NO TERMINAN (siguen mostrando nuevos logs)
docker-compose logs -f
# Presiona Ctrl + C para detener

# Ver logs solo de Airflow
docker-compose logs -f airflow-webserver
# Presiona Ctrl + C para detener

# Ver logs del pipeline Kedro (√∫ltimos 50)
docker-compose logs --tail=50 kedro-pipeline

# Ver logs en tiempo real del pipeline
docker-compose logs -f kedro-pipeline
# Presiona Ctrl + C para detener
```

**üí° Tip**: Usa `--tail=N` si quieres ver logs y que termine autom√°ticamente. Usa `-f` si quieres monitorear en tiempo real.

---

## üåê Paso 3: Ver Resultados en Airflow

### 3.1. Acceder a la interfaz de Airflow

1. **Abrir navegador** y ir a: `http://localhost:8080`

2. **Iniciar sesi√≥n**:
   - Usuario: `admin`
   - Contrase√±a: `admin`

### 3.2. Ver los DAGs disponibles

En la interfaz de Airflow ver√°s los siguientes DAGs:

1. **`kedro_ml_pipeline`**: Pipeline completo (preparaci√≥n + clasificaci√≥n + regresi√≥n)
2. **`kedro_classification_pipeline`**: Solo clasificaci√≥n
3. **`kedro_regression_pipeline`**: Solo regresi√≥n

### 3.3. Activar y ejecutar un DAG

1. **Buscar el DAG** `kedro_ml_pipeline` en la lista
2. **Activar el DAG**: Click en el toggle a la izquierda del nombre
3. **Ejecutar manualmente**: Click en el bot√≥n ‚ñ∂Ô∏è "Trigger DAG"

### 3.4. Monitorear la ejecuci√≥n

1. **Ver el estado**: Los c√≠rculos de colores indican el estado:
   - üü¢ Verde = Completado exitosamente
   - üü° Amarillo = En ejecuci√≥n
   - üî¥ Rojo = Error
   - ‚ö™ Gris = No ejecutado a√∫n

2. **Ver detalles de cada tarea**:
   - Click en el c√≠rculo de una tarea
   - Ver√°s: Logs, detalles, duraci√≥n, etc.

3. **Ver logs completos**:
   - Click en una tarea ‚Üí Click en "Log"
   - Ver√°s todos los mensajes de ejecuci√≥n

### 3.5. Entender el flujo del DAG

El DAG `kedro_ml_pipeline` ejecuta en este orden:

```
1. prepare_data       ‚Üí Limpia y prepara datos raw
2. create_features    ‚Üí Genera features para ML
3. train_classification ‚Üí Entrena 5 modelos de clasificaci√≥n
4. train_regression   ‚Üí Entrena 5 modelos de regresi√≥n
5. evaluate_models    ‚Üí Compara y selecciona mejores modelos
```

---

## üìä Paso 4: Usar DVC para Versionado

### 4.1. ¬øQu√© versiona DVC en este proyecto?

DVC rastrea autom√°ticamente (seg√∫n `dvc.yaml`):

**Datos procesados:**
- `data/02_intermediate/*.csv` (datos limpios)
- `data/03_primary/*.csv` (datos integrados)
- `data/05_model_input/*.csv` (datasets para ML)

**Modelos y m√©tricas:**
- `data/06_models/classification_results.pkl`
- `data/06_models/regression_results.pkl`
- `data/06_models/*_metrics.json`

**Visualizaciones:**
- `data/08_reporting/*.png` (gr√°ficos generados)

### 4.2. Ejecutar pipeline completo con DVC

```bash
# Reproducir todo el pipeline (preparaci√≥n ‚Üí evaluaci√≥n)
dvc repro

# Ver qu√© se ejecut√≥
dvc dag
```

### 4.3. Ver m√©tricas versionadas

```bash
# Ver todas las m√©tricas guardadas
dvc metrics show

# Ver m√©tricas espec√≠ficas
dvc metrics show data/06_models/classification_metrics.json
dvc metrics show data/06_models/regression_metrics.json

# Comparar m√©tricas entre commits
dvc metrics diff
```

### 4.4. Guardar cambios en DVC

```bash
# Despu√©s de ejecutar el pipeline, guardar en DVC
dvc add data/06_models/classification_metrics.json
dvc add data/06_models/regression_metrics.json

# Commit en Git (DVC crea archivos .dvc que se versionan en Git)
git add data/06_models/*.dvc .dvc/.gitignore
git commit -m "Actualizar m√©tricas de modelos"
```

### 4.5. Reproducir un stage espec√≠fico

```bash
# Solo preparar datos
dvc repro prepare

# Solo entrenar clasificaci√≥n
dvc repro train_classification

# Solo entrenar regresi√≥n
dvc repro train_regression
```

---

## üìÅ Paso 5: Ver Resultados Finales

### 5.1. M√©tricas de Modelos

**Clasificaci√≥n:**
```bash
# Ver m√©tricas (desde terminal)
type data\06_models\classification_metrics.json

# O abrir en navegador/editor
notepad data\06_models\classification_metrics.json
```

**Regresi√≥n:**
```bash
type data\06_models\regression_metrics.json
```

### 5.2. Visualizaciones Generadas

Ver gr√°ficos en:
```
data/08_reporting/
‚îú‚îÄ‚îÄ fase5_classification_comparison.png  (Comparaci√≥n modelos clasificaci√≥n)
‚îú‚îÄ‚îÄ fase5_regression_comparison.png      (Comparaci√≥n modelos regresi√≥n)
‚îú‚îÄ‚îÄ cleaning_process.png                 (Proceso de limpieza)
‚îú‚îÄ‚îÄ comparative_analysis.png             (An√°lisis comparativo)
‚îú‚îÄ‚îÄ genre_analysis.png                   (An√°lisis de g√©neros)
‚îî‚îÄ‚îÄ temporal_analysis.png                (An√°lisis temporal)
```

### 5.3. Reportes Finales

```bash
# Reporte de evaluaci√≥n (Fase 5)
type data\06_models\fase5_evaluation_report.json

# Reporte de comparaci√≥n (si existe)
type data\07_model_output\comparison_report.md
```

### 5.4. Ejecutar Notebooks para An√°lisis Detallado

```bash
# Abrir Jupyter (desde el contenedor o localmente)
jupyter notebook notebooks/

# Ejecutar en orden:
# 1. Fase1.ipynb - Comprensi√≥n del negocio
# 2. Fase2.ipynb - Exploraci√≥n de datos
# 3. Fase3.ipynb - Preparaci√≥n de datos
# 4. Fase4_Clasificacion.ipynb - Modelos de clasificaci√≥n
# 5. Fase4_Regresion.ipynb - Modelos de regresi√≥n
# 6. Fase5_Evaluacion.ipynb - Evaluaci√≥n y selecci√≥n
# 7. Fase6_Despliegue.ipynb - Conclusiones
```

---

## üîÑ Flujo Completo Recomendado

### Opci√≥n A: Ejecuci√≥n R√°pida (Primera vez)

```bash
# 1. Construir imagen
docker build -t kedro-ml .

# 2. Iniciar servicios
docker-compose up -d

# 3. Esperar 2-3 minutos y abrir Airflow
# http://localhost:8080
# Usuario: admin / Password: admin

# 4. Activar DAG "kedro_ml_pipeline"
# 5. Ejecutar manualmente
# 6. Ver resultados en data/06_models/
```

### Opci√≥n B: Con DVC (Versionado Completo)

```bash
# 1. Construir e iniciar (igual que Opci√≥n A)
docker build -t kedro-ml .
docker-compose up -d

# 2. Esperar a que termine la ejecuci√≥n autom√°tica
# 3. Verificar que se generaron los archivos

# 4. Versionar con DVC
dvc add data/06_models/classification_metrics.json
dvc add data/06_models/regression_metrics.json

# 5. Commit en Git
git add data/06_models/*.dvc .dvc/.gitignore
git commit -m "Guardar m√©tricas de modelos"

# 6. Ver m√©tricas
dvc metrics show
```

---

## üõë Detener Servicios

```bash
# Detener todos los servicios
docker-compose down

# Detener y eliminar vol√∫menes (‚ö†Ô∏è borra datos de Postgres)
docker-compose down -v

# Detener solo un servicio
docker-compose stop airflow-webserver
```

---

## üîß Troubleshooting

### ‚ö†Ô∏è Comando `logs -f` no termina
Si ejecutaste `docker-compose logs -f` y sigue mostrando logs:
- **Es normal**: El `-f` significa "follow" (seguir mostrando nuevos logs)
- **Para detener**: Presiona `Ctrl + C`
- **Para ver logs que terminan**: Usa `docker-compose logs --tail=100` (sin `-f`)

### Problema: Airflow no inicia
```bash
# Ver logs de errores (que terminan)
docker-compose logs --tail=100 airflow-webserver

# Ver logs en tiempo real (presiona Ctrl+C para detener)
docker-compose logs -f airflow-webserver

# Reiniciar servicios
docker-compose restart

# Reconstruir desde cero
docker-compose down -v
docker-compose up -d --build
```

### Problema: DAG activado pero no se ejecuta (nada pasa al presionar play) O DAG ejecuta pero falla

**üî¥ PROBLEMA COM√öN**: Falta el Airflow Scheduler.

**S√≠ntomas**:
- DAGs aparecen en la interfaz
- Puedes activarlos (toggle ON)
- Pero al presionar "Trigger DAG" no pasa nada

**Soluci√≥n**:
1. Verificar que el scheduler est√© corriendo:
   ```bash
   docker ps --filter "name=scheduler"
   ```
   
2. Si no aparece, agregar scheduler al `docker-compose.yml` (ya est√° incluido en la versi√≥n actualizada)

3. Reiniciar servicios:
   ```bash
   docker-compose down
   docker-compose up -d
   ```

4. Verificar que scheduler est√© activo:
   ```bash
   docker-compose ps
   ```
   
   Debes ver: `airflow-scheduler` con estado **Up**

5. Esperar 1-2 minutos para que el scheduler detecte los DAGs

### Problema: DAG no aparece en Airflow
- Verificar que el archivo est√° en `dags/`
- Verificar que no tiene errores de sintaxis
- Esperar 30-60 segundos (Airflow tarda en cargar DAGs)

### Problema: Puerto 8080 ocupado
```bash
# Cambiar puerto en docker-compose.yml
ports:
  - "8081:8080"  # Usar puerto 8081 en lugar de 8080
```

### Problema: Contenedor se detiene
```bash
# Ver logs del contenedor
docker logs ml-letterboxd-pipeline

# Ejecutar manualmente dentro del contenedor
docker exec -it ml-letterboxd-pipeline bash
kedro run
```

### Problema: DVC no encuentra archivos
```bash
# Verificar que los archivos existen
ls -la data/06_models/

# Reproducir el stage que genera el archivo
dvc repro train_classification  # Para classification_metrics.json
```

### üîç C√≥mo Revisar Errores en Airflow

Cuando un DAG falla (c√≠rculo rojo en Airflow UI):

#### **Paso 1: Ver el Error en la UI**

1. **Click en el DAG** que fall√≥ (ej: `kedro_classification`)
2. **Click en el c√≠rculo de color** de la tarea que fall√≥ (rojo = fallido)
3. **Click en "Log"** en el men√∫ que aparece
4. **Ver el error completo** en el log

#### **Paso 2: Verificar el Contenedor de Kedro**

```bash
# Verificar que el contenedor est√° corriendo
docker ps | Select-String "ml-letterboxd-pipeline"

# Si no est√° corriendo, iniciarlo
docker-compose up -d kedro-pipeline

# Probar el comando manualmente
docker exec -w /app ml-letterboxd-pipeline kedro run --pipeline=classification_pipeline
```

#### **Paso 3: Ver Logs desde Terminal**

```bash
# Ver logs del scheduler (√∫ltimos 100 l√≠neas)
docker-compose logs airflow-scheduler --tail 100

# Ver logs de una tarea espec√≠fica
docker-compose exec airflow-webserver ls -la /opt/airflow/logs/dag_id=kedro_classification/

# Ver logs del contenedor de Kedro
docker logs ml-letterboxd-pipeline --tail 50
```

#### **Paso 4: Errores Comunes y Soluciones**

**Error: "docker exec: No such container"**
- **Soluci√≥n**: El contenedor de Kedro no est√° corriendo
  ```bash
  docker-compose up -d kedro-pipeline
  ```

**Error: "cd /app: No such file or directory"**
- **Soluci√≥n**: Ya corregido. Los DAGs ahora usan `docker exec -w /app`. Si aparece, recarga los DAGs:
  ```bash
  docker-compose restart airflow-scheduler
  ```

**Error: "Pipeline 'classification_pipeline' not found"**
- **Soluci√≥n**: Verificar que el pipeline existe en `src/letterboxdml/pipelines/ml_modeling_pipeline.py`
  ```bash
  docker exec -w /app ml-letterboxd-pipeline kedro run --pipeline=eda_pipeline
  ```

**Error: "No module named 'X'"**
- **Soluci√≥n**: Instalar dependencia faltante en el contenedor
  ```bash
  docker exec -w /app ml-letterboxd-pipeline pip install <nombre_modulo>
  ```

#### **Paso 5: Verificar Estado Completo**

```bash
# Estado de todos los contenedores
docker-compose ps

# Todos deben estar "Up" y "healthy":
# ‚úÖ airflow-webserver - Up (healthy)
# ‚úÖ airflow-scheduler - Up (healthy)
# ‚úÖ ml-letterboxd-pipeline - Up (healthy)
# ‚úÖ postgres - Up (healthy)
```

---

## üìù Checklist Final

Despu√©s de ejecutar todo, verifica:

- [ ] ‚úÖ Airflow accesible en http://localhost:8080
- [ ] ‚úÖ DAGs visibles en Airflow
- [ ] ‚úÖ Pipeline ejecutado exitosamente (c√≠rculos verdes)
- [ ] ‚úÖ Archivos generados en `data/06_models/`:
  - [ ] `classification_metrics.json`
  - [ ] `regression_metrics.json`
  - [ ] `fase5_evaluation_report.json`
- [ ] ‚úÖ Visualizaciones en `data/08_reporting/`
- [ ] ‚úÖ (Opcional) M√©tricas versionadas en DVC

---

## üìö Recursos Adicionales

- **Kedro Docs**: https://kedro.readthedocs.io
- **Airflow Docs**: https://airflow.apache.org/docs
- **DVC Docs**: https://dvc.org/doc

---

**Autores**: Mathias Jara & Eduardo Gonzalez

