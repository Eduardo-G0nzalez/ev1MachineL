# üîß Soluci√≥n: Pipelines Fallan en Airflow por Timeout

## ‚ùå Problema Identificado

Todos los pipelines estaban fallando en Airflow porque las tareas exced√≠an el **timeout por defecto** de Airflow (aproximadamente 5-10 minutos). Los pipelines de Kedro, especialmente el de **unsupervised learning**, pueden tardar mucho tiempo:

- **Clustering**: B√∫squeda de k √≥ptimo puede tardar 10-15 minutos
- **Reducci√≥n Dimensional**: t-SNE y UMAP pueden tardar 20-30 minutos cada uno
- **Entrenamiento de Modelos**: Puede tardar 30-60 minutos dependiendo del tama√±o del dataset

## ‚úÖ Soluci√≥n Aplicada

Se agregaron **timeouts expl√≠citos** a todas las tareas de los DAGs de Airflow:

### Timeouts Configurados

| Pipeline/Tarea | Timeout | Raz√≥n |
|----------------|---------|-------|
| `data_preparation_pipeline` | 1 hora | Preparaci√≥n de datos puede ser extensa |
| `eda_pipeline` | 1 hora | An√°lisis exploratorio completo |
| `classification_pipeline` | 2 horas | Entrenamiento de m√∫ltiples modelos |
| `regression_pipeline` | 2 horas | Entrenamiento de m√∫ltiples modelos |
| `unsupervised_learning_pipeline` | 2 horas | Clustering + Reducci√≥n dimensional (muy intensivo) |
| `ml_modeling_pipeline` | 1 hora | Evaluaci√≥n de modelos |
| Tareas de evaluaci√≥n/reporte | 10-30 minutos | Operaciones r√°pidas |

### Archivos Modificados

1. `dags/kedro_ml_dag.py` - DAG principal con todos los pipelines
2. `dags/kedro_unsupervised_learning_dag.py` - DAG de aprendizaje no supervisado
3. `dags/kedro_classification_dag.py` - DAG de clasificaci√≥n
4. `dags/kedro_regression_dag.py` - DAG de regresi√≥n

### Ejemplo de Cambio

**Antes:**
```python
unsupervised_learning = BashOperator(
    task_id='run_unsupervised_learning_pipeline',
    bash_command='docker exec -w /app ml-letterboxd-pipeline kedro run --pipeline=unsupervised_learning_pipeline',
    dag=dag,
)
```

**Despu√©s:**
```python
unsupervised_learning = BashOperator(
    task_id='run_unsupervised_learning_pipeline',
    bash_command='docker exec -w /app ml-letterboxd-pipeline kedro run --pipeline=unsupervised_learning_pipeline',
    dag=dag,
    execution_timeout=timedelta(hours=2),  # Timeout de 2 horas
)
```

## üöÄ Pr√≥ximos Pasos

1. **Reiniciar Airflow Scheduler**:
   ```bash
   docker-compose restart airflow-scheduler
   ```

2. **Verificar que los DAGs se cargaron correctamente**:
   - Ir a http://localhost:8080
   - Verificar que los DAGs aparecen sin errores (no en rojo)

3. **Ejecutar un pipeline de prueba**:
   - Activar el DAG `kedro_unsupervised_learning`
   - Trigger manual del DAG
   - Monitorear que la tarea no falle por timeout

## üìä Monitoreo

Para monitorear el tiempo de ejecuci√≥n de las tareas:

1. En Airflow UI, ir a la tarea espec√≠fica
2. Ver "Duration" en el gr√°fico de ejecuci√≥n
3. Si una tarea se acerca al timeout, considerar:
   - Aumentar el timeout si es necesario
   - Optimizar el pipeline de Kedro para reducir tiempo de ejecuci√≥n
   - Dividir el pipeline en tareas m√°s peque√±as

## ‚ö†Ô∏è Notas Importantes

- Los timeouts son **m√°ximos**, no objetivos. Las tareas deber√≠an completarse antes del timeout.
- Si una tarea falla por timeout, Airflow la marcar√° como "failed" y puede reintentarla seg√∫n la configuraci√≥n de `retries`.
- El timeout se cuenta desde el inicio de la ejecuci√≥n de la tarea, no desde el inicio del DAG.

## üîç Verificaci√≥n

Para verificar que los cambios funcionaron:

```bash
# Ver logs del scheduler
docker-compose logs airflow-scheduler --tail 50

# Probar ejecutar un comando manualmente
docker exec airflow-scheduler docker exec -w /app ml-letterboxd-pipeline kedro run --pipeline=unsupervised_learning_pipeline
```

Si el comando funciona manualmente pero falla en Airflow, el problema puede ser:
- Timeout a√∫n insuficiente (aumentar m√°s)
- Problemas de recursos (CPU/RAM)
- Problemas de red entre contenedores

